#! python3
# -*- coding: utf-8 -*-
"""
# scrape_poe_maps.py - scrapes poe maps from http://pathofexile.gamepedia.com/Map
# (modified from scrape_poe_uniques.py)
"""

import requests, bs4, re, datetime, time, json
from bs4 import NavigableString
from multiprocessing.dummy import Pool as ThreadPool


base_url = 'http://pathofexile.gamepedia.com'
main_url = base_url + '/User:ARTyficial/MapData'

rx_search = re.compile(r'\+*\(([\d\.]+)\s[a-z]+\s([\d\.]+)[)]|(\+*[\d\.]+\%)|([\d\.]+-[\d\.]+)|(\([\d\.]+-[\d\.]+)\s\w+\s([\d\.]+-[\d\.]+\))|(-?\+?[\d\.]+)')
vendor_regex = re.compile('yield one|produced by', re.IGNORECASE)
maptype_regex = re.compile('Map type', re.IGNORECASE)


def write_file_headers():
    """
    info headers for MapList.txt

    :return: list
    """
    data = []
    d = datetime.datetime.now()
    now_time = d.strftime('%Y-%m-%d at %H:%M:%S')
    data.append('; Data from ' + main_url)
    data.append('; Comments can be made with ";", blank lines will be ignored.')
    data.append(';')
    data.append('; This file was auto-generated by scrape_poe_maps.py on {}'.format(now_time) + '\n')
    data.append('mapList := Object()')
    data.append('mapList["Unknown Map"] := "Map not recognised or not supported"\n')
    data.append('uniqueMapList := Object()')
    data.append('uniqueMapList["Unknown Map"] := "Map not recognised or not supported"\n')

    return data


def get_main_page(url):
    """
    Gets the main wiki page for Maps and parses out the links for each map
    and returns a list of the urls
    :param url: main page url
    :return: list of urls
    """
    map_urls = []
    print('Getting main page...')
    page = requests.get(url)
    page.raise_for_status()
    soup = bs4.BeautifulSoup(page.text, 'html.parser')
    map_table = soup.find_all('table', class_='wikitable')
    mapcount = 1
    for row in map_table[0].find_all('tr'):
        tds = row.find_all('td')
        if len(tds) == 0:    # exclude header row
            continue
        map_info = {}
        map_info['count'] = mapcount
        mapcount += 1
        map_info['tier'] = tds[0].text.strip()
        map_info['level'] = tds[1].text.strip()
        map_info['name'] = tds[2].text.strip()
        map_info['url'] = base_url + '/' + map_info['name'].replace(' ', '_')
        map_info['unique'] = tds[3].find('img')['alt'].strip()
        map_info['tileset'] = tds[4].text.strip()
        map_info['atlasposition'] = tds[5].text.strip()
        map_info['producedby'] = tds[6].text.strip()
        map_info['upgradesto'] = tds[7].text.strip()
        map_info['connectedto'] = tds[8].text.strip()
        map_info['boss'] = tds[9].text.strip()
        map_info['base'] = None
        if map_info['unique'] == 'yes':
            map_info['base'] = map_info['connectedto']
            map_info['connectedto'] = ''
        else:
            map_info['base'] = map_info['name']

        map_urls.append(map_info)
    return map_urls


def parse_map_data(map_info):
    """
    fetches the page for a map
    :param links:
    :return:
    """
    page = requests.get(map_info['url'])
    page.raise_for_status()
    soup = bs4.BeautifulSoup(page.text, 'html.parser')
    return build_data(soup, map_info)


def find_divcards(div):
    for h2 in div.find_all('h2'):
        if h2.find('span', id='Divination_cards'):
            return h2
    return None

	
def find_setting(div):
    for maptype in div.find_all(text=maptype_regex):
        return maptype.parent.next_sibling.replace(':', '').strip()
    return None


def build_data(data, mapinfo):
    """
    parse map data from the page
    :param data: BS4 ResultSet
    :return: list
    """
    map_data = dict(mapinfo)
    print('Getting data for {}'.format(map_data['name'].encode('utf8')))

    div = data.find('div', id='mw-content-text')  # main div containing our data

    # find the h2 element containing "Divination Cards" and list items following it
    map_data['divcards'] = []
    div_h2 = find_divcards(div)
    if div_h2 is not None:
        divlist = div_h2.find_next_siblings('ul')
        if divlist is not None:
            divcards = divlist[0].find_all('li')
        for divcard in divcards:
            map_data['divcards'].append(divcard.find('a').text)

    # find the text string "yield|produce one" to determine the vendor recipe for the map
    # map_data['vendor'] = find_vendor_recipe(div)

    # find the map setting (indoors/outdoors)
    map_data['setting'] = find_setting(div)

    #if map_data['unique'] == 'no' and map_data['tier'] != 'N/A' and int(map_data['tier']) != 15 and map_data['vendor'] is None:
    #    print('No vendor found for ' + map_data['name'])
    #if map_data['setting'] is None:
    #    print('No setting found for ' + map_data['name'])

    return map_data


def convert_data_to_AHK_readable_format(all_data):
    """
    This function takes the raw web page data, and converts it into lines that are readable by the
    Poe_item_info AHK script.
    :return:
    """

    # Read the descriptions of various maps
    with open('MapDescriptions.json', 'r') as f:
        map_descriptions = json.load(f)

    new_data = []
    vendor_map = {}
    unique_map = {}
    matchList = []
    for mymap in all_data:  # scan once to determine the lower tier map(s) that vendor up to each map
        #if mymap['vendor'] is not None and mymap['unique'] == 'no':
        #    if not mymap['vendor'] in vendor_map:
        #        vendor_map[mymap['vendor']] = []
        #    vendor_map[mymap['vendor']].append(mymap['name'])
        if mymap['unique'] == 'no':
            matchList.append(mymap['name'])
        if mymap['unique'] == 'yes' and mymap['base'] is not None:
            unique_map[mymap['base']] = mymap['name']

    new_data.append('matchList := ["' + '","'.join(matchList) + '"]\n')

    for mymap in all_data:
        if mymap['base'] is None:
            print('ERROR: Could not determine base map type for map: ' + mymap['name'])
            continue
        structureName = 'mapList'
        if mymap['unique'] == 'yes':
            structureName = 'uniqueMapList'
            new_data.append(';' + mymap['name'])
        line = structureName + '["' + mymap['base'] + '"] := "'
        line += 'Tier: ' + mymap['tier'] + ', Level: ' + mymap['level'] + ', Atlas position: ' + mymap['atlasposition']
        line += '`nTileset: ' + mymap['tileset']
        if mymap['setting'] is not None:
            line += ' (' + mymap['setting'] + ')'

        # Here we insert the prewritten text descriptions for the maps that have them
        #desc_key = 'maps'
        #if mymap['unique'] == 'yes':
        #    desc_key = 'uniqueMaps'
        #if mymap['base'] in map_descriptions[desc_key]:
        #    line += '`n`n' + map_descriptions[desc_key][mymap['base']]

        # Add on vendor recipes and connected maps
        if mymap['unique'] == 'no':
            info_lines = []
            #if mymap['base'] in vendor_map:
            #    for vend in vendor_map[mymap['base']]:
            #        vendor_lines.append('`n- Produced by three ' + vend + 's')
            if mymap['producedby']:
                info_lines.append('`nProduced by: ' + mymap['producedby'])
            if mymap['upgradesto']:
                info_lines.append('`nUpgrades to: ' + mymap['upgradesto'])
            if mymap['connectedto']:
                info_lines.append('`nConnected to: ' + mymap['connectedto'])
            if len(info_lines) > 0:
                line += '`n'
                for il in info_lines:
                    line += il

        # Add on unique version if one exists
        if mymap['name'] in unique_map:
            line += '`n`nUnique version of map: ' + unique_map[mymap['name']]

		# Add on divination cards
        if len(mymap['divcards']) > 0:
            line += '`n`nDivination cards:'
            for dc in mymap['divcards']:
                line += '`n- ' + dc

        line += '"\n'
        new_data.append(line)

    return new_data


def write(new_data):
    file = open('MapList.txt', 'ab')  # opens file for writing
    for row in new_data:
        file.write(row.encode('utf8'))
        file.write(b'\n')
    file.close()


def main():
    map_list = get_main_page(main_url)
    open('MapList.txt', 'w').close()  # create file (or overwrite it if it exists)
    write(write_file_headers())
    pool = ThreadPool(4)
    data = pool.map(parse_map_data, map_list)
    data.sort(key=lambda m: m['count'])
    x = convert_data_to_AHK_readable_format(data)
    write(x)
    pool.close()
    pool.join()


startTime = datetime.datetime.now()
main()
print('Program execution time: ',(datetime.datetime.now() - startTime))
