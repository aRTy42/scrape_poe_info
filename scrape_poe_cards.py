#! python3
# -*- coding: utf-8 -*-
"""
scrape_poe_cards.py - scrapes poe divination cards from http://pathofexile.gamepedia.com/Divination_card
(modified from scrape_poe_uniques.py)
"""

import requests, bs4, re, datetime, time
from bs4 import NavigableString


main_url = 'http://pathofexile.gamepedia.com/Divination_card'

unicode = re.compile(r'[^\x00-\x7F]+')  # regex that can be used to check for unicode chars in text


def get_file_headers():
    """
    info headers for DivinationCards.txt

    :return: list
    """
    data = []
    d = datetime.datetime.now()
    now_time = d.strftime('%Y-%m-%d at %H:%M:%S')
    data.append('; Data from ' + main_url)
    data.append('; Comments can be made with ";", blank lines will be ignored.')
    data.append(';')
    data.append('; This file was auto-generated by scrape_poe_cards.py on {}'.format(now_time) + '\n')
    data.append('divinationCardList := Object()\n')
    data.append('divinationCardList["Unknown Card"] := "You have found a new card, please report it!"\n')

    return data

def has_id(id):
    """
    a function used for searching a BS4 object. In this case, all cards are contained
    in a <tr> element, and only those elements that contain an 'id=' are the valid ones
    basically returns True if there is an id= which tells soup to grab the element
    :param id:
    :return:
    """
    return id is not None


def parse_card_data(link):
    """
    gets the element for each card then sends them to build_data()
    :param links:
    :return:
    """
    all_data = []
    page = requests.get(link)
    page.raise_for_status()
    soup = bs4.BeautifulSoup(page.text, 'html.parser')
    x = build_data(soup.find_all('tr', id=has_id))  # pick out the cards
    all_data.extend(x)

    return all_data


def build_data(data):
    """
    take a BS4 ResultSet of the cards and build a list containing each card
    The str.replace() done is an attempt to convert some unicode chars found in the data.
    :param data: BS4 ResultSet
    :return: list
    """
    all_data = []
    for tags in data:
        card_data = {}
        tag_content = tags.contents[0].text.rstrip()
        card_data['name'] = tags.contents[0].text.rstrip()
        print('Getting data for {}'.format(tag_content))
        locations = []
        location = ''
        for child in tags.contents[3].contents:
            # The drop locations are separated by <br> elements
            if child.name is not None and child.name == 'br':
                if len(location.strip()) > 0:
                    locations.append(location)
                location = ''
            elif child.name is not None and child.name == 'a':
                location += child.text
            elif isinstance(child, NavigableString):
                location += child.string
        if len(location.strip()) > 0:
            locations.append(location)
        card_data['locations'] = locations
        all_data.append(card_data)

    return all_data

def convert_data_to_AHK_readable_format(all_data):
    """
    This function takes the raw web page data, and converts it into lines that are readable by the
    Poe_item_info AHK script.
    :return:
    """
    new_data = []
    for card in all_data:
        line = 'divinationCardList["' + card['name'] + '"] := "Drop Restrictions:'
        for loc in card['locations']:
            line += '`n- ' + loc.strip()
        line += '"'
        new_data.append(line)

    return new_data


def write(new_data):

    file = open('DivinationCardList.txt', 'a')  # opens file for writing
    for row in new_data:
        file.write(row + '\n')  # write each line
    file.close()


def main():
    open('DivinationCardList.txt', 'w').close()  # create file (or overwrite it if it exists)
    write(get_file_headers())
    data = parse_card_data(main_url)
    x = convert_data_to_AHK_readable_format(data)
    write(x)

startTime = datetime.datetime.now()
main()
print('Program execution time: ',(datetime.datetime.now() - startTime))
